{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778cd488",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ” RTX 4070 + CUDA 13.1 í™˜ê²½ í…ŒìŠ¤íŠ¸\n",
    "Python 3.12.10\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ” ë¨¸ì‹ ëŸ¬ë‹ í™˜ê²½ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================\n",
    "# 1ï¸âƒ£ Python í™˜ê²½ í™•ì¸\n",
    "# ============================================\n",
    "print(\"\\nğŸ“Œ Python í™˜ê²½:\")\n",
    "print(f\"   ë²„ì „: {sys.version}\")\n",
    "print(f\"   ì‹¤í–‰ ê²½ë¡œ: {sys.executable}\")\n",
    "\n",
    "# ============================================\n",
    "# 2ï¸âƒ£ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸\n",
    "# ============================================\n",
    "print(\"\\nğŸ“Œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ í™•ì¸:\")\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f\"   âœ… NumPy: {np.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"   âŒ NumPy ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ\")\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(f\"   âœ… Pandas: {pd.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"   âŒ Pandas ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ\")\n",
    "\n",
    "try:\n",
    "    import sklearn\n",
    "    print(f\"   âœ… Scikit-learn: {sklearn.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"   âŒ Scikit-learn ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ\")\n",
    "\n",
    "try:\n",
    "    import matplotlib\n",
    "    print(f\"   âœ… Matplotlib: {matplotlib.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"   âŒ Matplotlib ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ\")\n",
    "\n",
    "# ============================================\n",
    "# 3ï¸âƒ£ PyTorch ë° CUDA í™•ì¸\n",
    "# ============================================\n",
    "print(\"\\nğŸ“Œ PyTorch í™˜ê²½:\")\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"   âœ… PyTorch ë²„ì „: {torch.__version__}\")\n",
    "    print(f\"   âœ… CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"   âœ… CUDA ë²„ì „: {torch.version.cuda}\")\n",
    "        print(f\"   âœ… cuDNN ë²„ì „: {torch.backends.cudnn.version()}\")\n",
    "        print(f\"   âœ… GPU ê°œìˆ˜: {torch.cuda.device_count()}\")\n",
    "        print(f\"   âœ… í˜„ì¬ GPU: {torch.cuda.current_device()}\")\n",
    "        print(f\"   âœ… GPU ì´ë¦„: {torch.cuda.get_device_name(0)}\")\n",
    "        \n",
    "        # GPU ë©”ëª¨ë¦¬ ì •ë³´\n",
    "        props = torch.cuda.get_device_properties(0)\n",
    "        print(f\"\\nğŸ’¾ GPU ë©”ëª¨ë¦¬ ì •ë³´:\")\n",
    "        print(f\"   ì´ ë©”ëª¨ë¦¬: {props.total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"   í• ë‹¹ëœ ë©”ëª¨ë¦¬: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "        print(f\"   ì˜ˆì•½ëœ ë©”ëª¨ë¦¬: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "        \n",
    "        # Compute Capability\n",
    "        print(f\"   Compute Capability: {props.major}.{props.minor}\")\n",
    "        \n",
    "        # cuDNN ë²¤ì¹˜ë§ˆí¬ ìƒíƒœ\n",
    "        print(f\"\\nâš™ï¸ ìµœì í™” ì„¤ì •:\")\n",
    "        print(f\"   cuDNN ë²¤ì¹˜ë§ˆí¬: {torch.backends.cudnn.benchmark}\")\n",
    "        print(f\"   cuDNN í™œì„±í™”: {torch.backends.cudnn.enabled}\")\n",
    "        \n",
    "        # GPU ì—°ì‚° í…ŒìŠ¤íŠ¸\n",
    "        print(f\"\\nğŸ§ª GPU ì—°ì‚° í…ŒìŠ¤íŠ¸:\")\n",
    "        import time\n",
    "        \n",
    "        # Warmup\n",
    "        x = torch.randn(5000, 5000).cuda()\n",
    "        y = torch.randn(5000, 5000).cuda()\n",
    "        for _ in range(3):\n",
    "            _ = torch.matmul(x, y)\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        # ì¸¡ì •\n",
    "        x = torch.randn(10000, 10000).cuda()\n",
    "        y = torch.randn(10000, 10000).cuda()\n",
    "        \n",
    "        start = time.time()\n",
    "        z = torch.matmul(x, y)\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        \n",
    "        print(f\"   10000x10000 í–‰ë ¬ ê³±ì…ˆ: {(end-start)*1000:.2f}ms\")\n",
    "        \n",
    "        # Mixed Precision í…ŒìŠ¤íŠ¸\n",
    "        x_fp16 = x.half()\n",
    "        y_fp16 = y.half()\n",
    "        \n",
    "        start = time.time()\n",
    "        z_fp16 = torch.matmul(x_fp16, y_fp16)\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        \n",
    "        print(f\"   FP16 í–‰ë ¬ ê³±ì…ˆ: {(end-start)*1000:.2f}ms\")\n",
    "        \n",
    "        print(f\"\\nâœ… GPUê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤! ğŸš€\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nâŒ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        print(\"ë“œë¼ì´ë²„ì™€ CUDA Toolkitì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"   âŒ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ============================================\n",
    "# 4ï¸âƒ£ TensorFlow í™•ì¸\n",
    "# ============================================\n",
    "print(\"\\nğŸ“Œ TensorFlow í™˜ê²½:\")\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"   âœ… TensorFlow ë²„ì „: {tf.__version__}\")\n",
    "    \n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        print(f\"   âœ… GPU ê°œìˆ˜: {len(gpus)}\")\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            print(f\"   âœ… GPU {i}: {gpu.name}\")\n",
    "    else:\n",
    "        print(\"   âš ï¸ GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"   âŒ TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ============================================\n",
    "# 5ï¸âƒ£ ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸\n",
    "# ============================================\n",
    "print(\"\\nğŸ“Œ ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬:\")\n",
    "\n",
    "libraries = {\n",
    "    'transformers': 'Transformers',\n",
    "    'xgboost': 'XGBoost',\n",
    "    'lightgbm': 'LightGBM',\n",
    "    'cv2': 'OpenCV',\n",
    "    'PIL': 'Pillow',\n",
    "    'tqdm': 'TQDM',\n",
    "    'wandb': 'Weights & Biases',\n",
    "    'optuna': 'Optuna'\n",
    "}\n",
    "\n",
    "for module, name in libraries.items():\n",
    "    try:\n",
    "        __import__(module)\n",
    "        print(f\"   âœ… {name}\")\n",
    "    except ImportError:\n",
    "        print(f\"   âš ï¸ {name} (ì„ íƒì‚¬í•­)\")\n",
    "\n",
    "# ============================================\n",
    "# 6ï¸âƒ£ Jupyter í™•ì¸\n",
    "# ============================================\n",
    "print(\"\\nğŸ“Œ Jupyter í™˜ê²½:\")\n",
    "\n",
    "try:\n",
    "    import jupyter\n",
    "    print(f\"   âœ… Jupyter ì„¤ì¹˜ë¨\")\n",
    "    print(f\"   ì‹¤í–‰ ëª…ë ¹ì–´: jupyter lab\")\n",
    "except ImportError:\n",
    "    print(\"   âŒ Jupyterê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ============================================\n",
    "# ìµœì¢… ê²°ê³¼\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… í™˜ê²½ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"\\nğŸ‰ ëª¨ë“  ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        print(\"ì´ì œ ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ì‘ì—…ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        print(\"\\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "        print(\"   - VS Code ë˜ëŠ” Cursorì—ì„œ Python íŒŒì¼ ìƒì„±\")\n",
    "        print(\"   - Jupyter Lab ì‹¤í–‰: jupyter lab\")\n",
    "        print(\"   - GPU ëª¨ë‹ˆí„°ë§: nvidia-smi -l 1\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ CUDA ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "        print(\"ë“œë¼ì´ë²„ì™€ CUDA Toolkitì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "except:\n",
    "    print(\"\\nâš ï¸ PyTorch ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e28bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "# GPU ìµœì í™” ì„¤ì • (RTX 6000 ë˜ëŠ” í˜„ì¬ GPU í™œìš©)\n",
    "def setup_cuda():\n",
    "    if torch.cuda.is_available():\n",
    "        # ì—°ì‚° ì†ë„ í–¥ìƒì„ ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ í™œì„±í™”\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        print(f\"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"ë©”ëª¨ë¦¬ ìš©ëŸ‰: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        print(\"âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "setup_cuda()\n",
    "\n",
    "# VitalDB ë°ì´í„° ë¡œë“œ ì˜ˆì‹œ (ì „ì²˜ë¦¬ ë¡œì§ í¬í•¨ ì˜ˆì •)\n",
    "def load_vital_data(file_path):\n",
    "    # ì‹¤ì œ ë°ì´í„° ë¡œë“œ ì‹œ 128GB RAMì„ í™œìš©í•´ ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "    print(f\"ë°ì´í„° ë¡œë“œ ì¤‘: {file_path}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e22ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# GPU í™•ì¸\n",
    "device = torch.device('cuda')\n",
    "print(f\"ğŸ”¥ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# ResNet50 ëª¨ë¸ ë¡œë“œ\n",
    "model = torchvision.models.resnet50(pretrained=True).to(device)\n",
    "model.eval()\n",
    "\n",
    "# ìƒ˜í”Œ ì´ë¯¸ì§€ë¡œ ì¶”ë¡ \n",
    "x = torch.randn(32, 3, 224, 224).to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(x)\n",
    "\n",
    "print(f\"âœ… ë°°ì¹˜ ì¶”ë¡  ì™„ë£Œ! Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10002612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import platform\n",
    "import psutil\n",
    "\n",
    "class CudaOptimizer:\n",
    "    @staticmethod\n",
    "    def setup():\n",
    "        # PyTorchì˜ cuDNN ë²¤ì¹˜ë§ˆí¬ í™œì„±í™” (ë™ì  ì…ë ¥ í¬ê¸°ê°€ ì•„ë‹ ë•Œ ì†ë„ ëŒ€í­ í–¥ìƒ)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            torch.backends.cuda.matmul.allow_tf32 = True  # Ampere/Blackwell ì•„í‚¤í…ì²˜ ê°€ì†\n",
    "            print(\"âœ… CUDA ìµœì í™” ì„¤ì • ì™„ë£Œ: cuDNN Benchmark ë° TF32 í™œì„±í™”\")\n",
    "        else:\n",
    "            print(\"âš ï¸ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def print_system_info():\n",
    "        print(f\"ğŸ–¥ï¸ ìš´ì˜ì²´ì œ: {platform.system()} {platform.release()}\")\n",
    "        print(f\"ğŸ§  CPU: {platform.processor()} (i9-14900K ê¸‰)\")\n",
    "        # 128GB RAM í™•ì¸\n",
    "        mem = psutil.virtual_memory()\n",
    "        print(f\"ğŸ“Š RAM: {mem.total / (1024**3):.2f} GB\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"ğŸ® GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def benchmark_gpu():\n",
    "        if not torch.cuda.is_available(): return\n",
    "        print(\"ğŸš€ GPU ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì¤‘...\")\n",
    "        # ê°„ë‹¨í•œ í–‰ë ¬ ì—°ì‚°ìœ¼ë¡œ ì„±ëŠ¥ ì²´í¬\n",
    "        x = torch.randn(5000, 5000).cuda()\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "        start.record()\n",
    "        torch.matmul(x, x)\n",
    "        end.record()\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"â±ï¸ 5000x5000 í–‰ë ¬ ì—°ì‚° ì†ë„: {start.elapsed_time(end):.2f} ms\")\n",
    "\n",
    "# ëª¨ë“ˆì²˜ëŸ¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "cuda_optimizer = CudaOptimizer()\n",
    "\n",
    "# --- ì—¬ê¸°ì„œë¶€í„° ê¸°ì¡´ ì½”ë“œ ì‹¤í–‰ ---\n",
    "cuda_optimizer.setup()\n",
    "cuda_optimizer.print_system_info()\n",
    "cuda_optimizer.benchmark_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bece643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1D-CNNì„ í™œìš©í•œ íŒŒí˜• íŠ¹ì§• ì¶”ì¶œê¸°\n",
    "class WaveformEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WaveformEncoder, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv_layers(x)\n",
    "\n",
    "# ì‹¬ë°•ì¶œëŸ‰ ì¶”ì • ë©”ì¸ ëª¨ë¸\n",
    "class CardiacOutputModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CardiacOutputModel, self).__init__()\n",
    "        self.encoder = WaveformEncoder()\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(64 * 250, 128), # ì…ë ¥ ê¸¸ì´ì— ë”°ë¼ ì¡°ì • í•„ìš”\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1) # ìµœì¢… CO ìˆ˜ì¹˜ ì¶œë ¥\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.regressor(x)\n",
    "\n",
    "print(\"âœ… ì‹¬ë°•ì¶œëŸ‰ ì¶”ì • ëª¨ë¸ ì•„í‚¤í…ì²˜ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vitaldb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. ë©”íƒ€ë°ì´í„° ë¡œë“œ (ì´ì „ ë‹¨ê³„ì—ì„œ ì„±ê³µí•œ ë¡œì§)\n",
    "df_trks = pd.read_csv(\"https://api.vitaldb.net/trks\")\n",
    "\n",
    "# 2. ë™ë§¥ì••(ART)ê³¼ ì‹¬ë°•ì¶œëŸ‰(CO)ì´ ìˆëŠ” ì¼€ì´ìŠ¤ ì°¾ê¸°\n",
    "art_cases = set(df_trks[df_trks['tname'].str.contains('ART|ABP', case=False, na=False)]['caseid'])\n",
    "co_cases = set(df_trks[df_trks['tname'].str.contains('CO', case=False, na=False) & \n",
    "                         ~df_trks['tname'].str.contains('CO2', case=False, na=False)]['caseid'])\n",
    "common_cases = list(art_cases.intersection(co_cases))\n",
    "\n",
    "print(f\"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ê³µí†µ ì¼€ì´ìŠ¤ ìˆ˜: {len(common_cases)}\")\n",
    "\n",
    "# 3. ë°ì´í„° ë¡œë“œ (í•¨ìˆ˜ëª… ì˜¤ë¥˜ í•´ê²°ì„ ìœ„í•œ ì§ì ‘ ë¡œë“œ ë°©ì‹)\n",
    "if common_cases:\n",
    "    case_id = common_cases[0]\n",
    "    case_trks = df_trks[df_trks['caseid'] == case_id]\n",
    "    \n",
    "    tname_art = case_trks[case_trks['tname'].str.contains('ART|ABP', case=False)]['tname'].iloc[0]\n",
    "    tname_co = case_trks[case_trks['tname'].str.contains('CO', case=False) & ~case_trks['tname'].str.contains('CO2')]['tname'].iloc[0]\n",
    "\n",
    "    print(f\"ğŸ“¡ {case_id}ë²ˆ ì¼€ì´ìŠ¤ ë¡œë“œ ì¤‘... ({tname_art}, {tname_co})\")\n",
    "    \n",
    "    # vitaldb ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ìµœì‹  í‘œì¤€ í•¨ìˆ˜ì¸ VitalFileì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    # ë§Œì•½ ì´ë§ˆì €ë„ ì—ëŸ¬ê°€ ë‚œë‹¤ë©´ ë°ì´í„° ë¡œë”© ë°©ì‹ ìì²´ë¥¼ URL ì§ì ‘ ì ‘ê·¼ìœ¼ë¡œ ì „í™˜í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "    try:\n",
    "        vf = vitaldb.VitalFile(case_id, [tname_art, tname_co])\n",
    "        data = vf.to_numpy([tname_art, tname_co], interval=0.01) # 100Hz\n",
    "        df_sample = pd.DataFrame(data, columns=['ABP', 'CO']).dropna()\n",
    "    except (AttributeError, Exception):\n",
    "        # ìµœí›„ì˜ ìˆ˜ë‹¨: VitalDB í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ í†µí•œ ë¡œë“œ\n",
    "        data = vitaldb.load_vital(case_id, [tname_art, tname_co], interval=0.01)\n",
    "        df_sample = pd.DataFrame(data, columns=['ABP', 'CO']).dropna()\n",
    "\n",
    "    print(f\"ğŸ“Š ë¡œë“œ ì„±ê³µ! ë°ì´í„° í–‰ ìˆ˜: {len(df_sample)}\")\n",
    "    print(df_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203d2307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class VitalDataset(Dataset):\n",
    "    def __init__(self, cases, window_size=1000, stride=100):\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        \n",
    "        # 128GB RAMì„ ë¯¿ê³  ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ìŒ“ìŠµë‹ˆë‹¤.\n",
    "        self._prepare_data(cases)\n",
    "\n",
    "    def _prepare_data(self, cases):\n",
    "        for case_id in cases:\n",
    "            # ì—¬ê¸°ì— ì•„ê¹Œ ì„±ê³µí•œ ë°ì´í„° ë¡œë“œ ë¡œì§ì„ ë„£ìŠµë‹ˆë‹¤.\n",
    "            # ë°ì´í„° ì •ê·œí™”(Min-Max)ì™€ í•„í„°ë§ í›„ ìœˆë„ìš°ë¡œ ìë¦…ë‹ˆë‹¤.\n",
    "            pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.inputs[idx]).unsqueeze(0) # (1, 1000)\n",
    "        y = torch.FloatTensor([self.targets[idx]])\n",
    "        return x, y\n",
    "\n",
    "print(\"ğŸš€ 128GB RAM ìµœì í™” ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì„¤ê³„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46deaf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì—­ ì„¤ì • ë° í•˜ë“œì›¨ì–´ ìµœì í™” (Mixed Precision)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# í•˜ë“œì›¨ì–´ ê°€ì† ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = GradScaler() # Mixed Precisionì„ ìœ„í•œ ìŠ¤ì¼€ì¼ëŸ¬\n",
    "\n",
    "print(f\"ğŸš€ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92928033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vitaldb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. ëª¨ë“  ì¼€ì´ìŠ¤ì™€ íŠ¸ë™ ì •ë³´ ë¡œë“œ\n",
    "print(\"ğŸ” VitalDB ë©”íƒ€ë°ì´í„° ë¡œë”© ì¤‘...\")\n",
    "df_cases = pd.read_csv(\"https://api.vitaldb.net/cases\")\n",
    "df_trks = pd.read_csv(\"https://api.vitaldb.net/trks\")\n",
    "\n",
    "# 2. ìœ ì—°í•œ ê²€ìƒ‰: 'ART' ë˜ëŠ” 'ABP'ë¥¼ í¬í•¨í•˜ê³ , 'CO'ë¥¼ í¬í•¨í•˜ë˜ 'CO2'ëŠ” ì œì™¸\n",
    "# i9-14900Kì˜ ì†ë„ë¡œ ìˆ˜ë§Œ ê°œì˜ íŠ¸ë™ëª…ì„ ìˆœì‹ê°„ì— ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "art_ids = df_trks[df_trks['tname'].str.contains('ART|ABP', case=False, na=False)]\n",
    "co_ids = df_trks[df_trks['tname'].str.contains('CO', case=False, na=False) & \n",
    "                 ~df_trks['tname'].str.contains('CO2', case=False, na=False)]\n",
    "\n",
    "# ì¼€ì´ìŠ¤ ID êµì§‘í•© ì°¾ê¸°\n",
    "common_caseids = set(art_ids['caseid']) & set(co_ids['caseid'])\n",
    "found_cases_info = []\n",
    "\n",
    "for cid in common_caseids:\n",
    "    found_cases_info.append({\n",
    "        'case_id': cid,\n",
    "        'abp_track': art_ids[art_ids['caseid'] == cid]['tname'].iloc[0],\n",
    "        'co_track': co_ids[co_ids['caseid'] == cid]['tname'].iloc[0]\n",
    "    })\n",
    "\n",
    "print(f\"âœ… ë°œê²¬ëœ ìœ íš¨ ì¼€ì´ìŠ¤: {len(found_cases_info)}ê°œ\")\n",
    "\n",
    "# 3. ë°ì´í„° ë¡œë“œ í…ŒìŠ¤íŠ¸ (ì„±ëŠ¥ ìµœì í™” ìœ„í•´ ì²˜ìŒ 20ê°œë§Œ ìš°ì„  ì‹œë„)\n",
    "samples = []\n",
    "if found_cases_info:\n",
    "    for info in found_cases_info[:20]:\n",
    "        try:\n",
    "            vf = vitaldb.VitalFile(info['case_id'], [info['abp_track'], info['co_track']])\n",
    "            data = vf.to_numpy([info['abp_track'], info['co_track']], interval=0.01)\n",
    "            df = pd.DataFrame(data, columns=['ABP', 'CO']).dropna()\n",
    "            \n",
    "            for j in range(0, len(df) - 1000, 500):\n",
    "                win = df['ABP'].iloc[j:j+1000].values\n",
    "                if np.mean(win) > 20: # ìµœì†Œí•œì˜ í’ˆì§ˆ ê²€ì‚¬\n",
    "                    samples.append((win, [np.max(win), np.min(win), np.mean(win)], df['CO'].iloc[j+1000]))\n",
    "        except: continue\n",
    "    print(f\"ğŸš€ í…ŒìŠ¤íŠ¸ ë¡œë“œ ì™„ë£Œ: ìƒ˜í”Œ {len(samples)}ê°œ í™•ë³´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed0b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 128GB RAMì— ì „ì²´ ë°ì´í„° ì ì¬\n",
    "\n",
    "import vitaldb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# ì „ì²´ ìƒ˜í”Œì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸\n",
    "all_samples = []\n",
    "\n",
    "print(f\"ğŸ“¦ ì „ì²´ {len(found_cases_info)}ê°œ ì¼€ì´ìŠ¤ ë°ì´í„° ì ì¬ ì‹œì‘ (128GB RAM ê°€ë™)...\")\n",
    "\n",
    "# i9-14900K ìˆœì°¨ì ìœ¼ë¡œ ë¡œë“œ (ì•ˆì •ì„± ìš°ì„ )\n",
    "for i, info in enumerate(found_cases_info):\n",
    "    try:\n",
    "        # ë°ì´í„° ë¡œë“œ\n",
    "        vf = vitaldb.VitalFile(info['case_id'], [info['abp_track'], info['co_track']])\n",
    "        data = vf.to_numpy([info['abp_track'], info['co_track']], interval=0.01)\n",
    "        df = pd.DataFrame(data, columns=['ABP', 'CO']).dropna()\n",
    "        \n",
    "        # ìœˆë„ìš° ìŠ¬ë¼ì´ì‹± ë° íŠ¹ì§• ì¶”ì¶œ\n",
    "        for j in range(0, len(df) - 1000, 500):\n",
    "            win = df['ABP'].iloc[j:j+1000].values\n",
    "            if np.mean(win) < 30 or np.mean(win) > 200: continue # ì˜í•™ì  ì´ìƒì¹˜ ì œê±°\n",
    "            \n",
    "            # [íŒŒí˜•, ì˜í•™ì ìˆ˜ì¹˜(SBP,DBP,MAP), íƒ€ê²Ÿ(CO)]\n",
    "            all_samples.append((\n",
    "                win.astype(np.float32), \n",
    "                np.array([np.max(win), np.min(win), np.mean(win)], dtype=np.float32), \n",
    "                np.float32(df['CO'].iloc[j+1000])\n",
    "            ))\n",
    "            \n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"ğŸ“ {i+1}/{len(found_cases_info)} ì¼€ì´ìŠ¤ ë¡œë“œ ì™„ë£Œ... í˜„ì¬ ì´ ìƒ˜í”Œ ìˆ˜: {len(all_samples)}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "print(f\"âœ… ìµœì¢… ì ì¬ ì™„ë£Œ! ì´ ìƒ˜í”Œ ìˆ˜: {len(all_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b5010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RTX 4070 ìµœì í™”: Mixed Precision í•˜ì´ë¸Œë¦¬ë“œ í•™ìŠµ\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# [Step 1] ëª¨ë¸ ìƒì„¸ ì •ì˜\n",
    "class CardiacHybridResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CardiacHybridResNet, self).__init__()\n",
    "        # íŒŒí˜• íŠ¹ì§• ì¶”ì¶œ (ResNet-1D ìŠ¤íƒ€ì¼)\n",
    "        self.waveform_extractor = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        # ì„ìƒ ìˆ˜ì¹˜ ë¸Œëœì¹˜ (SBP, DBP, MAP)\n",
    "        self.clinical_branch = nn.Sequential(\n",
    "            nn.Linear(3, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # íŠ¹ì§• ê²°í•© ë° íšŒê·€\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 + 16, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, wave, clin):\n",
    "        w_feat = self.waveform_extractor(wave).flatten(1)\n",
    "        c_feat = self.clinical_branch(clin)\n",
    "        combined = torch.cat([w_feat, c_feat], dim=1)\n",
    "        return self.fc(combined)\n",
    "\n",
    "# [Step 2] ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (ì´ë¯¸ RAMì— ìˆëŠ” all_samples í™œìš©)\n",
    "class VitalDataset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        w, c, t = self.samples[idx]\n",
    "        return torch.tensor(w).unsqueeze(0), torch.tensor(c), torch.tensor([t])\n",
    "\n",
    "# [Step 3] í•™ìŠµ ì„¤ì • ë° ì‹¤í–‰\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CardiacHybridResNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "scaler = GradScaler('cuda') # RTX 4070 ìµœì í™”\n",
    "\n",
    "# 128GB RAM ë°ì´í„°ë¥¼ DataLoaderë¡œ ì—°ê²°\n",
    "train_loader = DataLoader(VitalDataset(all_samples), batch_size=512, shuffle=True)\n",
    "\n",
    "print(f\"ğŸš€ {device}ì—ì„œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤. (ìƒ˜í”Œ ìˆ˜: {len(all_samples)})\")\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for wave, clin, target in train_loader:\n",
    "        wave, clin, target = wave.to(device), clin.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed Precision ì ìš© (VRAM 12GB íš¨ìœ¨ ê·¹ëŒ€í™”)\n",
    "        with autocast('cuda'):\n",
    "            output = model(wave, clin)\n",
    "            loss = criterion(output, target)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/50 | Loss: {epoch_loss/len(train_loader):.6f}\")\n",
    "\n",
    "print(\"âœ… í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™” ë° ì„ìƒìš© ì„±ëŠ¥ í‰ê°€ ë³´ê³ ì„œ\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# 1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ê°’ ì‚°ì¶œ\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for wave, clin, target in train_loader: # ì‹¤ì œë¡œëŠ” ë¶„í• ëœ í…ŒìŠ¤íŠ¸ ë¡œë” ì‚¬ìš© ê¶Œì¥\n",
    "        output = model(wave.to(device), clin.to(device))\n",
    "        y_true.extend(target.numpy().flatten())\n",
    "        y_pred.extend(output.cpu().numpy().flatten())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# 2. ì‹œê°í™” ë¦¬í¬íŠ¸ ìƒì„±\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# A. Correlation Plot (ëŒ€í•™ì›ìš©: ì„ í˜•ì  ì„±ëŠ¥ ì¦ëª…)\n",
    "ax[0].scatter(y_true, y_pred, alpha=0.4, color='teal', s=10)\n",
    "ax[0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
    "ax[0].set_xlabel('Actual Cardiac Output (L/min)')\n",
    "ax[0].set_ylabel('Predicted Cardiac Output (L/min)')\n",
    "ax[0].set_title(f'Correlation Plot (r = {np.corrcoef(y_true, y_pred)[0,1]:.3f})')\n",
    "ax[0].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# B. Bland-Altman Plot (ì·¨ì—…ìš©: ì‹¤ì œ ì„ìƒ ì˜¤ì°¨ ë¶„ì„)\n",
    "sm.graphics.mean_diff_plot(y_true, y_pred, ax=ax[1])\n",
    "ax[1].set_title('Bland-Altman Plot: Clinical Agreement')\n",
    "ax[1].set_xlabel('Mean of Actual and Predicted')\n",
    "ax[1].set_ylabel('Difference (Actual - Predicted)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. ì„ìƒ ì§€í‘œ ì¶œë ¥\n",
    "rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "mae = np.mean(np.abs(y_true - y_pred))\n",
    "print(f\"ğŸ“Š ì„ìƒ í‰ê°€ ìš”ì•½:\")\n",
    "print(f\"- Root Mean Squared Error (RMSE): {rmse:.3f} L/min\")\n",
    "print(f\"- Mean Absolute Error (MAE): {mae:.3f} L/min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b446a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XAI (ì„¤ëª… ê°€ëŠ¥í•œ AI) - Attention Map ì‹œê°í™”\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "# --- Grad-CAMì„ ìœ„í•œ Hook ì„¤ì • ---\n",
    "gradients = None\n",
    "activations = None\n",
    "\n",
    "def backward_hook(module, grad_input, grad_output):\n",
    "    global gradients\n",
    "    gradients = grad_output[0]\n",
    "\n",
    "def forward_hook(module, input, output):\n",
    "    global activations\n",
    "    activations = output\n",
    "\n",
    "# ëª¨ë¸ì˜ ë§ˆì§€ë§‰ í•©ì„±ê³± ì¸µ ë‹¤ìŒì— Hookì„ ê²ë‹ˆë‹¤.\n",
    "# waveform_extractorì˜ ë§ˆì§€ë§‰ ReLU ì¸µ(ì¸ë±ìŠ¤ 5)ì„ íƒ€ê²Ÿìœ¼ë¡œ í•©ë‹ˆë‹¤.\n",
    "target_layer = model.waveform_extractor[5]\n",
    "target_layer.register_forward_hook(forward_hook)\n",
    "target_layer.register_full_backward_hook(backward_hook)\n",
    "\n",
    "# --- ì‹œê°í™” í•¨ìˆ˜ ---\n",
    "def generate_gradcam(wave_tensor, clin_tensor, model, device):\n",
    "    model.eval()\n",
    "    # 1. ìˆœì „íŒŒ (Forward Pass)\n",
    "    output = model(wave_tensor.to(device), clin_tensor.to(device))\n",
    "    \n",
    "    # 2. ì—­ì „íŒŒ (Backward Pass) - ì˜ˆì¸¡ê°’ ìì²´ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°\n",
    "    model.zero_grad()\n",
    "    output.backward()\n",
    "    \n",
    "    # 3. Grad-CAM ê³„ì‚°\n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2])\n",
    "    for i in range(activations.shape[1]):\n",
    "        activations[:, i, :] *= pooled_gradients[i]\n",
    "        \n",
    "    heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "    heatmap = F.relu(heatmap) # ì–‘ì˜ ì˜í–¥ë ¥ë§Œ ê³ ë ¤\n",
    "    heatmap /= torch.max(heatmap) # ì •ê·œí™”\n",
    "    \n",
    "    return heatmap.cpu().detach().numpy(), output.item()\n",
    "\n",
    "# --- ìƒ˜í”Œ ì¶”ì¶œ ë° ì‹œê°í™” ì‹¤í–‰ ---\n",
    "# DataLoaderì—ì„œ ìƒ˜í”Œ 3ê°œë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "data_iter = iter(train_loader)\n",
    "waves, clins, targets = next(data_iter)\n",
    "waves, clins, targets = waves[:3], clins[:3], targets[:3]\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "for i in range(3):\n",
    "    wave = waves[i].unsqueeze(0)\n",
    "    clin = clins[i].unsqueeze(0)\n",
    "    target = targets[i].item()\n",
    "    \n",
    "    # Grad-CAM ìƒì„± (ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©)\n",
    "    heatmap, pred = generate_gradcam(wave, clin, model, 'cuda')\n",
    "    \n",
    "    # ì›ë³¸ íŒŒí˜• (1, 1000)\n",
    "    original_wave = wave.squeeze().cpu().numpy()\n",
    "    \n",
    "    # íˆíŠ¸ë§µ ë¦¬ì‚¬ì´ì¦ˆ: (1000,) -> (1, 1000) 2D ë°°ì—´ë¡œ ìœ ì§€\n",
    "    heatmap_resized = cv2.resize(heatmap, (1000, 1))\n",
    "    \n",
    "    # [ìˆ˜ì •] np.newaxisë¥¼ ì œê±°í•˜ê³  heatmap_resizedë¥¼ ì§ì ‘ ì „ë‹¬\n",
    "    axs[i].plot(original_wave, color='black', label='ABP Waveform', alpha=0.7, lw=1.5)\n",
    "    \n",
    "    # íˆíŠ¸ë§µ ì˜¤ë²„ë ˆì´\n",
    "    im = axs[i].imshow(heatmap_resized, cmap='jet', aspect='auto', \n",
    "                       alpha=0.5, extent=[0, 1000, original_wave.min(), original_wave.max()])\n",
    "    \n",
    "    axs[i].set_title(f\"Sample {i+1} | True CO: {target:.2f} | Pred CO: {pred:.2f}\")\n",
    "    axs[i].set_ylabel(\"Pressure (mmHg)\")\n",
    "    axs[i].legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa093b36",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ ê³ ë„í™” - ì˜¤ì°¨ ë³´ì • ë° ì²œì¥ íš¨ê³¼ í•´ê²°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e01c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³ ì¶œë ¥ ì§‘ì¤‘ í•™ìŠµì„ ìœ„í•œ í†µí•© ìµœì í™” ì½”ë“œ\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# 1. ê³ ì¶œë ¥ êµ¬ê°„ ì§‘ì¤‘ í•™ìŠµì„ ìœ„í•œ Weighted MSE Loss\n",
    "class WeightedMSELoss(nn.Module):\n",
    "    def __init__(self, high_threshold=40.0, weight_factor=3.5):\n",
    "        super().__init__()\n",
    "        self.high_threshold = high_threshold\n",
    "        self.weight_factor = weight_factor\n",
    "        self.mse = nn.MSELoss(reduction='none')\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        loss = self.mse(pred, target)\n",
    "        # ì‹¤ì œê°’ì´ thresholdë³´ë‹¤ í¬ë©´ ì˜¤ì°¨ì— ê°€ì¤‘ì¹˜ë¥¼ ê³±í•¨\n",
    "        weights = torch.where(target > self.high_threshold, self.weight_factor, 1.0)\n",
    "        return torch.mean(loss * weights)\n",
    "\n",
    "# 2. í•˜ë“œì›¨ì–´ ì ì¬ë ¥ì„ í™œìš©í•œ Deeper ResNet ì„¤ê³„\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_ch, out_ch, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm1d(out_ch), nn.ReLU(),\n",
    "            nn.Conv1d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_ch)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_ch, out_ch, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm1d(out_ch)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.relu(self.conv(x) + self.shortcut(x))\n",
    "\n",
    "class AdvancedCardiacResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.wave_extractor = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=7, stride=2, padding=3), nn.BatchNorm1d(64), nn.ReLU(),\n",
    "            ResidualBlock(64, 128, stride=2),\n",
    "            ResidualBlock(128, 256, stride=2),\n",
    "            ResidualBlock(256, 512, stride=2),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.clinical_branch = nn.Sequential(nn.Linear(3, 32), nn.ReLU())\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 + 32, 128), nn.ReLU(),\n",
    "            nn.Dropout(0.3), # ê³¼ì í•© ë°©ì§€\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, wave, clin):\n",
    "        w = self.wave_extractor(wave).flatten(1)\n",
    "        c = self.clinical_branch(clin)\n",
    "        return self.fc(torch.cat([w, c], dim=1))\n",
    "\n",
    "# 3. í†µí•© í•™ìŠµ íŒŒì´í”„ë¼ì¸\n",
    "def run_optimized_training(samples):\n",
    "    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    device = torch.device('cuda')\n",
    "    model = AdvancedCardiacResNet().to(device)\n",
    "    # ê³ ì¶œë ¥ ë°ì´í„°(CO > 40)ì— 3.5ë°° ê°€ì¤‘ì¹˜ ë¶€ì—¬\n",
    "    criterion = WeightedMSELoss(high_threshold=40.0, weight_factor=3.5) \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "    scaler = GradScaler('cuda') # ìµœì‹  ê·œê²©\n",
    "\n",
    "    # DataLoader ì„¤ì • (num_workers=0ìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´)\n",
    "    # ì´ë¯¸ 128GB RAMì— ì ì¬ëœ all_samplesë¥¼ ì‚¬ìš©\n",
    "    dataset = VitalDataset(samples)\n",
    "    loader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=0)\n",
    "\n",
    "    print(f\"ğŸš€ RTX 4070 ê³ ë„í™” í•™ìŠµ ì‹œì‘ (ìƒ˜í”Œ ìˆ˜: {len(samples)})\")\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for wave, clin, target in loader:\n",
    "            wave, clin, target = wave.to(device), clin.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast('cuda'): # Mixed Precision ê°€ì†\n",
    "                output = model(wave, clin)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/50 | Weighted Loss: {epoch_loss/len(loader):.6f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# --- ì‹¤ì œ ì‹¤í–‰ ---\n",
    "# 'all_samples'ê°€ ì´ì „ ë‹¨ê³„ì—ì„œ ì ì¬ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "if 'all_samples' in globals() and len(all_samples) > 0:\n",
    "    trained_model = run_optimized_training(all_samples)\n",
    "    print(\"âœ… ëª¨ë“  í•™ìŠµì´ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"âŒ 'all_samples' ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë°ì´í„° ì ì¬ ì½”ë“œë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd12ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³ ë„í™” ëª¨ë¸ ìµœì¢… ê²€ì¦ (Correlation & Bland-Altman)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë” ì¬ì •ì˜ (ì•ˆì „í•˜ê²Œ loader ìƒì„±)\n",
    "final_dataset = VitalDataset(all_samples)\n",
    "final_loader = DataLoader(final_dataset, batch_size=512, shuffle=False, num_workers=0)\n",
    "\n",
    "# 2. ê³ ë„í™” ëª¨ë¸ ì˜ˆì¸¡ê°’ ì‚°ì¶œ\n",
    "trained_model.eval()\n",
    "y_true_new = []\n",
    "y_pred_new = []\n",
    "\n",
    "print(\"âš¡ RTX 4070ìœ¼ë¡œ ìµœì¢… ì˜ˆì¸¡ê°’ ì‚°ì¶œ ì¤‘...\")\n",
    "with torch.no_grad():\n",
    "    for wave, clin, target in final_loader:\n",
    "        output = trained_model(wave.to('cuda'), clin.to('cuda'))\n",
    "        y_true_new.extend(target.numpy().flatten())\n",
    "        y_pred_new.extend(output.cpu().numpy().flatten())\n",
    "\n",
    "y_true_new = np.array(y_true_new)\n",
    "y_pred_new = np.array(y_pred_new)\n",
    "\n",
    "# 3. ì‹œê°í™” ë¦¬í¬íŠ¸ ìƒì„±\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# A. Correlation Plot (r ìˆ˜ì¹˜ í™•ì¸)\n",
    "r_val = np.corrcoef(y_true_new, y_pred_new)[0,1]\n",
    "ax[0].scatter(y_true_new, y_pred_new, alpha=0.4, color='darkorange', s=10)\n",
    "ax[0].plot([y_true_new.min(), y_true_new.max()], [y_true_new.min(), y_true_new.max()], 'r--', lw=2)\n",
    "ax[0].set_title(f'Advanced Model Correlation (r = {r_val:.3f})')\n",
    "ax[0].set_xlabel('Actual CO (L/min)')\n",
    "ax[0].set_ylabel('Predicted CO (L/min)')\n",
    "\n",
    "# B. Bland-Altman Plot (ì˜¤ì°¨ í¸í–¥ í™•ì¸)\n",
    "sm.graphics.mean_diff_plot(y_true_new, y_pred_new, ax=ax[1])\n",
    "ax[1].set_title('Advanced Model Bland-Altman Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… ìµœì¢… ìƒê´€ê³„ìˆ˜(r): {r_val:.3f}\")\n",
    "print(f\"âœ… ìµœì¢… MAE: {np.mean(np.abs(y_true_new - y_pred_new)):.3f} L/min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b45a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³ ë„í™” ëª¨ë¸ ì „ìš© XAI ì‹œê°í™” (Grad-CAM)\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Grad-CAMì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”\n",
    "gradients = None\n",
    "activations = None\n",
    "\n",
    "def backward_hook(module, grad_input, grad_output):\n",
    "    global gradients\n",
    "    gradients = grad_output[0]\n",
    "\n",
    "def forward_hook(module, input, output):\n",
    "    global activations\n",
    "    activations = output\n",
    "\n",
    "# AdvancedCardiacResNet ëª¨ë¸ì˜ ë§ˆì§€ë§‰ Residual Block ë‚´ë¶€ Conv ì¸µ íƒ€ê²ŸíŒ…\n",
    "target_layer = trained_model.wave_extractor[4].conv[3]\n",
    "target_layer.register_forward_hook(forward_hook)\n",
    "target_layer.register_full_backward_hook(backward_hook)\n",
    "\n",
    "def visualize_final_xai(num_samples=3):\n",
    "    # ìƒ˜í”Œ ë°ì´í„° ì¶”ì¶œ\n",
    "    waves, clins, targets = next(iter(final_loader))\n",
    "    \n",
    "    fig, axs = plt.subplots(num_samples, 1, figsize=(15, 4 * num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        wave = waves[i].unsqueeze(0).to('cuda')\n",
    "        clin = clins[i].unsqueeze(0).to('cuda')\n",
    "        \n",
    "        # Grad-CAM ìƒì„±\n",
    "        trained_model.eval()\n",
    "        output = trained_model(wave, clin)\n",
    "        trained_model.zero_grad()\n",
    "        output.backward()\n",
    "        \n",
    "        pooled_gradients = torch.mean(gradients, dim=[0, 2])\n",
    "        for j in range(activations.shape[1]):\n",
    "            activations[:, j, :] *= pooled_gradients[j]\n",
    "            \n",
    "        heatmap = torch.mean(activations, dim=1).squeeze().cpu().detach().numpy()\n",
    "        heatmap = np.maximum(heatmap, 0)\n",
    "        heatmap /= (np.max(heatmap) + 1e-8)\n",
    "        \n",
    "        # ì‹œê°í™”\n",
    "        original_wave = waves[i].squeeze().numpy()\n",
    "        heatmap_resized = cv2.resize(heatmap, (1000, 1))\n",
    "        \n",
    "        axs[i].plot(original_wave, color='black', alpha=0.7, label='ABP Wave')\n",
    "        axs[i].imshow(heatmap_resized, cmap='jet', aspect='auto', \n",
    "                       alpha=0.5, extent=[0, 1000, original_wave.min(), original_wave.max()])\n",
    "        axs[i].set_title(f\"Sample {i+1} | True: {targets[i].item():.2f} | Pred: {output.item():.2f}\")\n",
    "        axs[i].legend(loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_final_xai()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77f762a",
   "metadata": {},
   "source": [
    "# í•™ë¬¸ì  ì—„ë°€ì„± (Academic Rigor) ê³ ë„í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3512931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™˜ì ID í¬í•¨ ë°ì´í„° ì¬êµ¬ì„±\n",
    "\n",
    "all_samples = [] # ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "\n",
    "print(f\"ğŸ“¦ í™˜ì IDë¥¼ í¬í•¨í•˜ì—¬ {len(found_cases_info)}ê°œ ì¼€ì´ìŠ¤ ì¬ì ì¬ ì‹œì‘...\")\n",
    "\n",
    "for i, info in enumerate(found_cases_info):\n",
    "    try:\n",
    "        vf = vitaldb.VitalFile(info['case_id'], [info['abp_track'], info['co_track']])\n",
    "        data = vf.to_numpy([info['abp_track'], info['co_track']], interval=0.01)\n",
    "        df = pd.DataFrame(data, columns=['ABP', 'CO']).dropna()\n",
    "        \n",
    "        for j in range(0, len(df) - 1000, 500):\n",
    "            win = df['ABP'].iloc[j:j+1000].values\n",
    "            if np.mean(win) < 30 or np.mean(win) > 200: continue\n",
    "            \n",
    "            # 4ë²ˆì§¸ ìš”ì†Œë¡œ info['case_id']ë¥¼ ë°˜ë“œì‹œ ì¶”ê°€\n",
    "            all_samples.append((\n",
    "                win.astype(np.float32), \n",
    "                np.array([np.max(win), np.min(win), np.mean(win)], dtype=np.float32), \n",
    "                np.float32(df['CO'].iloc[j+1000]),\n",
    "                info['case_id'] # <--- Patient-wise êµ¬ë¶„ì„ ìœ„í•œ í•µì‹¬\n",
    "            ))\n",
    "            \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"ğŸ“ {i+1} ì¼€ì´ìŠ¤ ì™„ë£Œ... í˜„ì¬ ìƒ˜í”Œ ìˆ˜: {len(all_samples)}\")\n",
    "    except: continue\n",
    "\n",
    "print(f\"âœ… ì¬ì ì¬ ì™„ë£Œ! ì´ ìƒ˜í”Œ ìˆ˜: {len(all_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064037d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ ë° í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ì •ì˜\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "\n",
    "# 4ê°œ ìš”ì†Œë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (W, C, T, Case_ID)\n",
    "class VitalDataset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        # w, c, t, case_id 4ê°œë¥¼ ë°›ì•„ì„œ í•™ìŠµìš© 3ê°œë§Œ ë°˜í™˜\n",
    "        w, c, t, _ = self.samples[idx] \n",
    "        return torch.tensor(w).unsqueeze(0), torch.tensor(c), torch.tensor([t])\n",
    "\n",
    "# [ê³ ë„í™”] CNN-LSTM í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ (TemporalCardiacNet)\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_ch, out_ch, 3, stride=stride, padding=1),\n",
    "            nn.BatchNorm1d(out_ch), nn.ReLU(),\n",
    "            nn.Conv1d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm1d(out_ch)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.shortcut = nn.Sequential(nn.Conv1d(in_ch, out_ch, 1, stride=stride), nn.BatchNorm1d(out_ch))\n",
    "    def forward(self, x):\n",
    "        return torch.relu(self.conv(x) + self.shortcut(x))\n",
    "\n",
    "class TemporalCardiacNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, 7, stride=2, padding=3), nn.BatchNorm1d(64), nn.ReLU(),\n",
    "            ResidualBlock(64, 128, stride=2),\n",
    "            ResidualBlock(128, 256, stride=2)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(input_size=256, hidden_size=128, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        self.clinical_branch = nn.Sequential(nn.Linear(3, 32), nn.ReLU())\n",
    "        self.fc = nn.Sequential(nn.Linear(256 + 32, 64), nn.ReLU(), nn.Linear(64, 1))\n",
    "\n",
    "    def forward(self, wave, clin):\n",
    "        feat = self.cnn(wave).permute(0, 2, 1) # (Batch, Seq, 256)\n",
    "        lstm_out, _ = self.lstm(feat)\n",
    "        context = lstm_out[:, -1, :] # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í… ì¶”ì¶œ\n",
    "        c = self.clinical_branch(clin)\n",
    "        return self.fc(torch.cat([context, c], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95c4c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™˜ì ë‹¨ìœ„ 5-Fold êµì°¨ ê²€ì¦ í†µí•© ì‹¤í–‰\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 1. ì„¤ì • ë° ì¤€ë¹„\n",
    "unique_patient_ids = np.unique([s[3] for s in all_samples]) # 4ë²ˆì§¸ ìš”ì†Œì¸ case_id ì¶”ì¶œ\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "# ê°€ì¤‘ì¹˜ ì†ì‹¤ í•¨ìˆ˜ ì •ì˜\n",
    "criterion = WeightedMSELoss(high_threshold=40.0, weight_factor=3.5)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(unique_patient_ids)):\n",
    "    print(f\"\\nğŸŒ€ Fold {fold + 1} í•™ìŠµ ì‹œì‘ (CNN-LSTM ê°€ë™)...\")\n",
    "    \n",
    "    train_patients = set(unique_patient_ids[train_idx])\n",
    "    val_patients = set(unique_patient_ids[val_idx])\n",
    "    \n",
    "    # í™˜ì ë‹¨ìœ„ ë°ì´í„° ë¶„ë¦¬\n",
    "    train_data = [s for s in all_samples if s[3] in train_patients]\n",
    "    val_data = [s for s in all_samples if s[3] in val_patients]\n",
    "    \n",
    "    # 128GB RAM í™˜ê²½ì„ ê³ ë ¤í•œ ìµœì  ë¡œë” ì„¤ì •\n",
    "    train_loader = DataLoader(VitalDataset(train_data), batch_size=256, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(VitalDataset(val_data), batch_size=256, shuffle=False)\n",
    "    \n",
    "    # ëª¨ë¸ ë° ìµœì í™” ì„¤ì •\n",
    "    model = TemporalCardiacNet().to('cuda')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "    scaler = GradScaler('cuda')\n",
    "\n",
    "    # í•™ìŠµ ë£¨í”„ (25 ì—í­)\n",
    "    for epoch in range(25):\n",
    "        model.train()\n",
    "        for wave, clin, target in train_loader:\n",
    "            wave, clin, target = wave.to('cuda'), clin.to('cuda'), target.to('cuda')\n",
    "            optimizer.zero_grad()\n",
    "            with autocast('cuda'):\n",
    "                output = model(wave, clin)\n",
    "                loss = criterion(output, target)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "    # ê²€ì¦ ë° ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "    model.eval()\n",
    "    preds, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for wave, clin, target in val_loader:\n",
    "            output = model(wave.to('cuda'), clin.to('cuda'))\n",
    "            preds.extend(output.cpu().numpy().flatten())\n",
    "            actuals.extend(target.numpy().flatten())\n",
    "    \n",
    "    # ìƒê´€ê³„ìˆ˜ ë° MAE ê¸°ë¡\n",
    "    r_val, _ = pearsonr(actuals, preds)\n",
    "    mae_val = np.mean(np.abs(np.array(actuals) - np.array(preds)))\n",
    "    cv_scores.append(r_val)\n",
    "    mae_scores.append(mae_val)\n",
    "    print(f\"âœ… Fold {fold+1} ì™„ë£Œ | r: {r_val:.4f} | MAE: {mae_val:.4f}\")\n",
    "\n",
    "# 3. ìµœì¢… í†µê³„ ë³´ê³ \n",
    "print(f\"\\nğŸ“Š [ìµœì¢… ë³´ê³ ì„œ]\")\n",
    "print(f\"- ìƒê´€ê³„ìˆ˜ (r): {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}\")\n",
    "print(f\"- í‰ê·  ì˜¤ì°¨ (MAE): {np.mean(mae_scores):.4f} Â± {np.std(mae_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold 2 ì´ìƒì¹˜ ë¶„ì„ ë° ì˜¤ì°¨ ì‹œê°í™” (Technical Insight)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Fold 2ì˜ ì˜¤ì°¨ ë°ì´í„° í”„ë ˆì„ ìƒì„±\n",
    "# (Fold 2 ê²€ì¦ ì‹œ ì €ì¥í–ˆë˜ actuals, preds, case_ids í™œìš©)\n",
    "error_df = pd.DataFrame({\n",
    "    'actual': actuals,\n",
    "    'pred': preds,\n",
    "    'abs_error': np.abs(np.array(actuals) - np.array(preds))\n",
    "})\n",
    "\n",
    "# 2. ì˜¤ì°¨ ë¶„ì„ ì‹œê°í™”: Residual Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(error_df['actual'], error_df['pred'] - error_df['actual'], alpha=0.3, color='crimson')\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.title('Fold 2: Residual Plot')\n",
    "plt.xlabel('Actual CO')\n",
    "plt.ylabel('Residual (Pred - Actual)')\n",
    "\n",
    "# 3. ìµœì•…ì˜ ì˜¤ì°¨ ìƒ˜í”Œ íŒŒí˜• ì‹œê°í™” (Worst 1)\n",
    "worst_idx = error_df['abs_error'].idxmax()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_data[worst_idx][0], color='black') # val_dataëŠ” Fold 2ì˜ ê²€ì¦ ë°ì´í„°\n",
    "plt.title(f\"Worst Sample in Fold 2 (Error: {error_df['abs_error'].max():.2f})\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"ğŸ“Š Fold 2 ë¶„ì„ ê²°ê³¼:\")\n",
    "print(f\"- ì‹¤ì œ CO í‰ê· : {np.mean(actuals):.2f} | ì˜ˆì¸¡ CO í‰ê· : {np.mean(preds):.2f}\")\n",
    "print(f\"- ìµœëŒ€ ì˜¤ì°¨ ë°œìƒ êµ¬ê°„: ì‹¤ì œ CO {error_df.loc[worst_idx, 'actual']:.2f} ë¶€ê·¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc0cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention ê¸°ë°˜ ê³ ë„í™” ëª¨ë¸ í†µí•© ì‹¤í–‰ ì½”ë“œ\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "# 1. ëª¨ë¸ êµ¬ì„± ìš”ì†Œ (Attention ë° í•˜ì´ë¸Œë¦¬ë“œ êµ¬ì¡°)\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim, 1)\n",
    "    def forward(self, x):\n",
    "        weights = torch.softmax(torch.tanh(self.attn(x)), dim=1)\n",
    "        return torch.sum(weights * x, dim=1)\n",
    "\n",
    "class AttentionCardiacNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, 7, stride=2, padding=3), nn.BatchNorm1d(64), nn.ReLU(),\n",
    "            ResidualBlock(64, 128, stride=2),\n",
    "            ResidualBlock(128, 256, stride=2)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(256, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        self.attention = AttentionLayer(256) \n",
    "        self.clinical_branch = nn.Sequential(nn.Linear(3, 32), nn.ReLU())\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256 + 32, 128), nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    def forward(self, wave, clin):\n",
    "        feat = self.cnn(wave).permute(0, 2, 1)\n",
    "        lstm_out, _ = self.lstm(feat)\n",
    "        context = self.attention(lstm_out)\n",
    "        c = self.clinical_branch(clin)\n",
    "        return self.fc(torch.cat([context, c], dim=1))\n",
    "\n",
    "# 2. í†µí•© í•™ìŠµ ì‹¤í–‰ í•¨ìˆ˜\n",
    "def run_attention_training(train_samples, val_samples):\n",
    "    device = torch.device('cuda')\n",
    "    model = AttentionCardiacNet().to(device)\n",
    "    \n",
    "    # Fold 2ì˜ ê³ ì¶œë ¥ ì˜¤ì°¨(image_7a2c9f)ë¥¼ ì¡ê¸° ìœ„í•´ ê°€ì¤‘ì¹˜ ê°•í™”\n",
    "    criterion = WeightedMSELoss(high_threshold=40.0, weight_factor=4.5) \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    # ì •ë°€í•œ ìˆ˜ë ´ì„ ìœ„í•œ ìŠ¤ì¼€ì¤„ëŸ¬ ì¶”ê°€\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "    scaler = GradScaler('cuda')\n",
    "\n",
    "    # 128GB RAM ìì›ì„ í™œìš©í•œ ì•ˆì •ì ì¸ ë¡œë” ì„¤ì •\n",
    "    train_loader = DataLoader(VitalDataset(train_samples), batch_size=256, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(VitalDataset(val_samples), batch_size=256, shuffle=False)\n",
    "\n",
    "    print(f\"ğŸ”¥ RTX 4070 ê°€ë™: Attention ê¸°ë°˜ ê³ ë„í™” í•™ìŠµ ì‹œì‘...\")\n",
    "\n",
    "    for epoch in range(30): # 30ì—í­ ì§‘ì¤‘ í•™ìŠµ\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for wave, clin, target in train_loader:\n",
    "            wave, clin, target = wave.to(device), clin.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast('cuda'):\n",
    "                output = model(wave, clin)\n",
    "                loss = criterion(output, target)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # ê²€ì¦ ë‹¨ê³„\n",
    "        model.eval()\n",
    "        val_preds, val_actuals = [], []\n",
    "        with torch.no_grad():\n",
    "            for wave, clin, target in val_loader:\n",
    "                output = model(wave.to(device), clin.to(device))\n",
    "                val_preds.extend(output.cpu().numpy().flatten())\n",
    "                val_actuals.extend(target.numpy().flatten())\n",
    "        \n",
    "        r_val, _ = pearsonr(val_actuals, val_preds)\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        scheduler.step(avg_train_loss) # í•™ìŠµë¥  ìë™ ì¡°ì •\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/30 | Loss: {avg_train_loss:.4f} | Val r: {r_val:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# 3. ì‹¤ì œ í˜¸ì¶œ (Fold 1 ë°ì´í„°ë¥¼ ì˜ˆì‹œë¡œ ì‹¤í–‰)\n",
    "# train_data, val_dataê°€ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "if 'train_data' in globals():\n",
    "    trained_model = run_attention_training(train_data, val_data)\n",
    "else:\n",
    "    print(\"âŒ train_dataê°€ ì—†ìŠµë‹ˆë‹¤. 5-Fold ë¶„í•  ì½”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline ëª¨ë¸ ì •ì˜ ë° ì´ˆê¸°í™”\n",
    "\n",
    "# 1. ì´ˆê¸° ëª¨ë¸(AdvancedCardiacResNet) í´ë˜ìŠ¤ê°€ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "baseline_model = AdvancedCardiacResNet().to('cuda')\n",
    "\n",
    "# 2. (ì„ íƒ ì‚¬í•­) ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ê°€ ìˆë‹¤ë©´ ë¡œë“œ\n",
    "# baseline_model.load_state_dict(torch.load('baseline_best_model.pth')) \n",
    "\n",
    "baseline_model.eval()\n",
    "print(\"âœ… Baseline ëª¨ë¸(AdvancedCardiacResNet) ì¤€ë¹„ ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eee910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline vs Attention-LSTM ì„±ëŠ¥ ë¹„êµ ì¸¡ì •\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def measure_baseline_performance(model, sample_data, device='cuda'):\n",
    "    model.eval()\n",
    "    # sample_dataì—ì„œ waveì™€ clin ì¶”ì¶œ\n",
    "    wave, clin = sample_data[0].to(device), sample_data[1].to(device)\n",
    "    \n",
    "    # GPU ì˜ˆì—´ (Warm-up)\n",
    "    for _ in range(100):\n",
    "        with torch.no_grad():\n",
    "            _ = model(wave, clin)\n",
    "    \n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    repetitions = 500\n",
    "    timings = np.zeros((repetitions, 1))\n",
    "    \n",
    "    print(f\"âš¡ Baseline ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì • ì¤‘...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for rep in range(repetitions):\n",
    "            starter.record()\n",
    "            _ = model(wave, clin)\n",
    "            ender.record()\n",
    "            \n",
    "            torch.cuda.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings[rep] = curr_time\n",
    "\n",
    "    avg_latency = np.sum(timings) / repetitions\n",
    "    throughput = 1000 / avg_latency\n",
    "    hourly_proc_time = (3600 / 10) * (avg_latency / 1000)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š [Baseline ëª¨ë¸ ì„±ëŠ¥ ê²°ê³¼]\")\n",
    "    print(f\"- í‰ê·  ì§€ì—° ì‹œê°„ (Latency): {avg_latency:.3f} ms\")\n",
    "    print(f\"- ì´ˆë‹¹ ì²˜ë¦¬ëŸ‰ (Throughput): {throughput:.1f} cases/sec\")\n",
    "    print(f\"- 1ì‹œê°„ ë¶„ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œê°„: {hourly_proc_time:.4f} ì´ˆ\")\n",
    "    \n",
    "    return avg_latency, throughput\n",
    "\n",
    "# ì¸¡ì • ì‹¤í–‰\n",
    "base_lat, base_tp = measure_baseline_performance(baseline_model, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e856d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶”ë¡  ì†ë„ ì •ë°€ ì¸¡ì •\n",
    "\n",
    "import time\n",
    "\n",
    "def measure_inference_speed(model, sample_data, device='cuda'):\n",
    "    model.eval()\n",
    "    wave, clin = sample_data[0].to(device), sample_data[1].to(device)\n",
    "    \n",
    "    # 1. Warm-up: GPUë¥¼ ì˜ˆì—´í•˜ì—¬ ì´ˆê¸° ì§€ì—° ì‹œê°„ ì œê±°\n",
    "    for _ in range(100):\n",
    "        _ = model(wave, clin)\n",
    "    \n",
    "    # 2. ì •ë°€ ì¸¡ì • ì‹œì‘\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    repetitions = 500\n",
    "    timings = np.zeros((repetitions, 1))\n",
    "    \n",
    "    print(f\"âš¡ {device.upper()} ì¶”ë¡  ì†ë„ ì¸¡ì • ì¤‘ (500íšŒ ë°˜ë³µ)...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for rep in range(repetitions):\n",
    "            starter.record()\n",
    "            _ = model(wave, clin)\n",
    "            ender.record()\n",
    "            \n",
    "            # GPU ì—°ì‚° ì™„ë£Œ ëŒ€ê¸°\n",
    "            torch.cuda.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings[rep] = curr_time\n",
    "\n",
    "    avg_time = np.sum(timings) / repetitions\n",
    "    fps = 1000 / avg_time # ì´ˆë‹¹ ì²˜ë¦¬ ê°€ëŠ¥í•œ ìƒ˜í”Œ ì„¸íŠ¸ ìˆ˜\n",
    "    \n",
    "    print(f\"\\nğŸ“Š [ì¶”ë¡  ì„±ëŠ¥ ê²°ê³¼]\")\n",
    "    print(f\"- í‰ê·  ì§€ì—° ì‹œê°„ (Latency): {avg_time:.3f} ms\")\n",
    "    print(f\"- ì´ˆë‹¹ ì²˜ë¦¬ëŸ‰ (Throughput): {fps:.1f} cases/sec\")\n",
    "    print(f\"- 1ì‹œê°„ ë¶„ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì˜ˆìƒ ì‹œê°„: {360 * avg_time / 1000:.2f} ì´ˆ\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° í•œ ê°œ ì¶”ì¶œ\n",
    "sample_batch = next(iter(val_loader))\n",
    "single_sample = (sample_batch[0][:1], sample_batch[1][:1]) # ë°°ì¹˜ í¬ê¸° 1ë¡œ ì„¤ì •\n",
    "\n",
    "measure_inference_speed(trained_model, single_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ae2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline vs Attention-LSTM ì„±ëŠ¥ ë¹„êµ ì¸¡ì •\n",
    "\n",
    "# 1. Baseline ëª¨ë¸ ì¸¡ì •\n",
    "print(\"ğŸ“‹ [1/2] Baseline ëª¨ë¸ ì¸¡ì • ì¤‘...\")\n",
    "base_lat, base_tp = measure_baseline_performance(baseline_model, sample_input)\n",
    "\n",
    "# 2. Attention-LSTM ëª¨ë¸ ì¸¡ì • (trained_model ë˜ëŠ” attention_model)\n",
    "print(\"\\nğŸ“‹ [2/2] Attention-LSTM ëª¨ë¸ ì¸¡ì • ì¤‘...\")\n",
    "# ì•ì„œ í•™ìŠµ ì™„ë£Œí•œ ê³ ë„í™” ëª¨ë¸ ë³€ìˆ˜ëª…ì„ ë„£ìœ¼ì„¸ìš” (ì˜ˆ: trained_model)\n",
    "adv_lat, adv_tp = measure_baseline_performance(trained_model, sample_input)\n",
    "\n",
    "# 3. í•œëˆˆì— ë¹„êµí•˜ê¸° ìœ„í•œ í…Œì´ë¸” ì¶œë ¥\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"{'Metric':<25} | {'Baseline':<12} | {'Attention-LSTM':<15}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Latency (ms)':<25} | {base_lat:<12.3f} | {adv_lat:<15.3f}\")\n",
    "print(f\"{'Throughput (cases/sec)':<25} | {base_tp:<12.1f} | {adv_tp:<15.1f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# íš¨ìœ¨ì„± ë¶„ì„ (ì„±ëŠ¥ ì €í•˜ìœ¨ ê³„ì‚°)\n",
    "slowdown = (adv_lat - base_lat) / base_lat * 100\n",
    "print(f\"ğŸ’¡ ë¶„ì„: ëª¨ë¸ ê³ ë„í™”ë¡œ ì¸í•´ ì§€ì—° ì‹œê°„ì´ ì•½ {slowdown:.1f}% ì¦ê°€í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
